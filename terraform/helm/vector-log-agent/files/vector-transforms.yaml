transforms:
  k8s_logs:
    type: remap
    inputs:
      - kubernetes_logs
    source: |
      .k8s = del(.kubernetes)
      .k8s.cluster = "${K8S_CLUSTER:?err}"

      node_labels = del(.k8s.node_labels)
      .k8s.node_labels."node.kubernetes.io/instance-type" = node_labels."node.kubernetes.io/instance-type"
      .k8s.node_labels."topology.gke.io/zone" = node_labels."topology.gke.io/zone"
      .k8s.node_name = del(.k8s.pod_node_name)

      .min_log_level_to_retain = .k8s.annotations."aptos.dev/min-log-level-to-retain"

      del(.k8s.container_id)
      del(.k8s.container_image_id)
      # TODO: add finops cost center label
      del(.k8s.namespace_labels)
      del(.k8s.pod_ips)
      del(.k8s.pod_owner)
      del(.k8s.pod_uid)

      # Remove all annotations.
      del(.k8s.annotations)

      # Retain only Forge labels.
      k8s_labels = del(.k8s.labels)
      if contains(.k8s.cluster, "forge") {
        .k8s.labels.app.kubernetes."io/name" = k8s_labels.app.kubernetes."io/name"
        .k8s.labels."forge-namespace" = k8s_labels."forge-namespace"
      }

      del(."@timestamp.nanos")
      del(.source_type)
      del(.hostname)
      del(.namespace)
      del(.file)

  normalized_logs:
    type: remap
    inputs:
      - k8s_logs
    source: |
      parsed_message, err = parse_json(.message)
      if err == null && is_object(parsed_message) {
        del(.message)
        . = merge!(., parsed_message, deep: true)
        # if the parsed_message didn't have a `.message` property fall back to some common fields under `.data`
        if !exists(.message) {
          fallback_message, err = string(parsed_message.data.message) ?? string(parsed_message.data.event) ?? string(parsed_message.data.error) ?? string(parsed_message.data.name) ?? string(parsed_message.data.method)
          if err == null {
            .message = fallback_message
          }
        }
      }
      if exists(.fields) {
        . = merge!(., .fields)
        del(.fields)
      }
      if exists(.level) && is_string(.level) {
        .level = downcase!(.level);
      }
      if !exists(.message) && exists(.msg) {
        .message = del(.msg)
      }
      parsed_timestamp, err = parse_timestamp(.timestamp, "%+") # parse as ISO 8601 / RFC 3339 according to https://github.com/vectordotdev/vrl/blob/650547870a16c66dcfab01ec382cfdc23415d85b/lib/core/src/conversion.rs#L249C6-L249C8
      if err == null {
        .timestamp = parsed_timestamp
      }

  # This stage filters forge logs based off of node index and log level.
  # It retains all logs for nodes 0-4 and only error logs for nodes 5+.
  # The `aptos.dev/min-log-level-to-retain` pod annotation overrides the default behavior.
  filter_forge_logs:
    type: filter
    inputs:
      - normalized_logs
    condition: |
      aptos_node_index = to_int(parse_regex(.k8s.pod_name, r'^aptos-node-(?P<node_index>\d+)-.*').node_index ?? 0) ?? 0

      is_forge_log = contains(to_string!(.k8s.cluster), "forge") && exists(.k8s.labels."forge-namespace")
      is_low_index_forge_node = aptos_node_index < 5
      is_error_log = (.level == "error")

      log_level_values = {
        "trace": 1,
        "debug": 2,
        "info": 3, 
        "warn": 4,
        "error": 5,
      }

      has_log_level_annotation = .min_log_level_to_retain != null
      log_level_annotation_value = get(log_level_values, [.min_log_level_to_retain]) ?? null
      log_value = get(log_level_values, [.level]) ?? null
      is_allowed_log_level = (log_level_annotation_value != null && log_value != null && log_value >= log_level_annotation_value) ?? false

      retain_log = 
        !is_forge_log || 
        (has_log_level_annotation && is_allowed_log_level) || 
        (!has_log_level_annotation && is_low_index_forge_node) ||
        (!has_log_level_annotation && is_error_log)

      retain_log

  delete_temp_fields:
    type: remap
    inputs:
      - filter_forge_logs
    source: del(.min_log_level_to_retain)

  final_logs:
    type: filter
    inputs:
      - delete_temp_fields
    # temporarily filter out noisy logs in vector until https://github.com/aptos-labs/aptos-core/pull/13965 lands in mainnet release
    # temporarily filter out noisy logs from https://aptos-org.slack.com/archives/C06TH3DH7SB/p1721328005384169?thread_ts=1720695143.603089&cid=C06TH3DH7SB until lands in mainnet release
    # temporarily filter out noisy logs from https://aptos-org.slack.com/archives/C08L5ETPN8Y/p1743105723097009 until code change lands to downgrade them to trace level
    condition: |
      if is_string(.message) {
        message = to_string!(.message)
        if .level == "debug" && ( .message == "ReceiveOrderVote" || .message == "sent_peer_monitoring_response" ) {
          return false
        }
        if starts_with(message, "ReceiveVote") || starts_with(message, "OrderVote:") || starts_with(message, "Receive commit vote BlockInfo") {
          return false
        }
        if .level == "debug" && contains(message, "Received response for expired request_id") {
          return false
        }
        if starts_with(message, "Received an order vote not in the next 100 rounds") {
          return false
        }
        if starts_with(message, "[Pipeline] Block") {
          return false
        }
        if starts_with(message, "Advance execution root") {
          return false
        }
        if starts_with(message, "Received block payload") {
          return false
        }
        if starts_with(message, "Received commit decision") {
          return false
        }
        if starts_with(message, "Received ordered block") {
          return false
        }
        if starts_with(message, "Receive ") {
          return false
        }
        if starts_with(message, "Advance head") {
          return false
        }
        if starts_with(message, "Advance execution root") {
          return false
        }
        if starts_with(message, "Advance signing root") {
          return false
        }
        if starts_with(message, "Computed new use case tracking set") {
          return false
        }
        if starts_with(message, "send_direct_send_message") {
          return false
        }
        if starts_with(message, "Calculated ledger update") {
          return false
        }
        if starts_with(message, "Enqueued transaction chunk") {
          return false
        }
        if starts_with(message, "commit_ledger") {
          return false
        }
        if starts_with(message, "ledger_update") {
          return false
        }
        if starts_with(message, "execute_block") {
          return false
        }
        if starts_with(message, "pre_commit_block") {
          return false
        }
        if starts_with(message, "Updated with a new root block") {
          return false
        }
        if starts_with(message, "Block dropped") {
          return false
        }
        if starts_with(message, "Applied a new transaction output chunk") {
          return false
        }
        if starts_with(message, "Committed a new transaction chunk") {
          return false
        }
        if starts_with(message, "Write usage at version") {
          return false
        }
        if starts_with(message, "Processing decisioned randomness") {
          return false
        }
        if starts_with(message, "Received a consensus commit notification") {
          return false
        }
        if starts_with(message, "[BlockSTM]: Parallel[2] execution completed") {
          return false
        }
        # Moved this out of the indexers namespace filter since we sometimes stream off of PFNs, like in Shelbynet
        if starts_with(message, "[Indexer Fullnode] Found new highest known version") {
          return false
        }
        # Indexer Processors/GRPC
        if contains(to_string!(.k8s.namespace), "indexer") {
          if starts_with(message, "[Data Service] One chunk of transactions") {
            return false
          }
          if starts_with(message, "[Data Service] All chunks of transactions") {
            return false
          }
          if starts_with(message, "[Data Service] Fetching data from in-memory cache") {
            return false
          }
          if starts_with(message, "In-memory cache lookup") {
            return false
          }
          if starts_with(message, "Applied a new transaction output chunk") {
            return false
          }
          if starts_with(message, "Committed a new transaction chunk") {
            return false
          }
          if starts_with(message, "Split transactions into two epochs") {
            return false
          }
          if starts_with(message, "Table info parsed successfully") {
            return false
          }
          if starts_with(message, "Preparing to fetch transactions") {
            return false
          }
          if starts_with(message, "Calculated ledger update") {
            return false
          }
          if starts_with(message, "Enqueued transaction chunk") {
            return false
          }
          if starts_with(message, "Write usage at version") {
            return false
          }
          if starts_with(message, "Successfully converted transactions") {
            return false
          }
          if starts_with(message, "[DB] Table handle written to the rocksdb successfully") {
            return false
          }
          if starts_with(message, "Active discovered peers") {
            return false
          }
        }
      }
      true
