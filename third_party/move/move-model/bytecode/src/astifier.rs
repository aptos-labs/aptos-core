// Copyright © Aptos Foundation
// Parts of the project are originally copyright © Meta Platforms, Inc.
// SPDX-License-Identifier: Apache-2.0

//! Converts stackless bytecode into Model AST.
//!
//! See [this article](https://medium.com/leaningtech/solving-the-structured-control-flow-problem-once-and-for-all-5123117b1ee2)
//! for an introduction into how this code works. This is an excellent high-level overview of
//! the decompilation problem and the solution which is adapted here. The article is a relative
//! light read and hence leaves many details open, which an implementation has to determine.
//!
//! In a nutshell, the decompilation from stackless bytecode into the Model AST here
//! works in the steps outlined below
//!
//! # 1. Cleanup
//!
//! The code is cleaned up such that there are no jump proxies of the form `label L; goto L1`.
//! Also, adjacent sequential blocks are merged, and fallthrough branches replaced by explicit
//! jumps. It is important for the algorithm to produce best results if intermediate
//! blocks are removed.
//!
//! # 2. Loop Analysis
//!
//! Compute loop information using the `fat_loop` module. This allows to distinguish
//! backward jumps from forward jumps. The fat_loop bails out if the control graph is
//! not reducible.
//!
//! # 3. Topological Sorting
//!
//! Topological sort the blocks using forward edges only. For those blocks which are not related
//! in the partial order, group blocks such that all those blocks belonging to a loop are not
//! interleaved with any blocks outside the loop in the order. This order exists because of
//! the regularity of the control flow graph: each loop has a unique header block.
//!
//! # 4. Raw AST Generation
//!
//! The article linked above describes well how blocks can be used to synthesize structured
//! code. However, it leaves open when to open blocks and when to close them.
//!
//! The way how this is implemented here is by maintaining a so-called `block_stack`
//! which contains information of open blocks, and then walking over the blocks in the
//! order as determined in (3). During this walk, blocks are created and sorted into the
//! stack depending on the type of construct. For example, for a loop a block is pushed
//! when the header is reached. For forward jumps, a block is inserted into the stack
//! such that it is nested underneath existing blocks which encloses the jump target.
//!
//! Loops are closed when their exit label is reached. For the above
//! example, the inner loop is closed on bytecode `label L2` and the
//! outer on `label 3`. Some loops which have been opened may never
//! be associated with a label (for example, in an
//! `if goto L1 else goto L2` where one of the targets is a back jump
//! in a loop). Those are closed when an enclosing loop's label
//! is reached.
//!
//! # 5. AST Transformations
//!
//! Once the raw AST has been generated as described above, it is
//! run through a few transformation steps:
//!
//! 1. *Conditional Transformation* discovers if-then-else
//!    expressions from the nested loops as generated by the core
//!    algorithm. This is based on pattern matching against the AST.
//!    It is possible that the rules used here need to be extended
//!    over time, as it is kind of heuristic.
//! 2. *Assignment Transformation* removes obsoletes assignments
//!    by propagating reaching definitions. It also introduces
//!    `let` declarations for temporaries scoped to a block.
//!
//! A number of tools are defined in this module to perform AST
//! transformations, including a data flow analysis
//! framework for ASTs in the form as generated by the core
//! algorithms. They are kept local here but can be pulled
//! out of this module if more general use cases arise.

use crate::{
    dataflow_domains::{AbstractDomain, JoinResult, MapDomain, SetDomain},
    fat_loop::{build_loop_info, FatLoopFunctionInfo},
    function_target::FunctionTarget,
    stackless_bytecode::{AttrId, Bytecode, Label, Operation as BytecodeOperation},
    stackless_control_flow_graph::{BlockId, StacklessControlFlowGraph},
};
use abstract_domain_derive::AbstractDomain;
use itertools::Itertools;
use log::{debug, log_enabled, Level};
use move_binary_format::file_format::CodeOffset;
use move_model::{
    ast::{Exp, ExpData, Operation, Pattern, TempIndex},
    exp_builder::ExpBuilder,
    exp_rewriter::ExpRewriterFunctions,
    model::{GlobalEnv, Loc, NodeId, QualifiedInstId, StructId},
    symbol::Symbol,
    ty::{ReferenceKind, Type},
};
use std::{
    cmp::Ordering,
    collections::{BTreeMap, BTreeSet},
};
use topological_sort::TopologicalSort;
use try_match::match_ok;

const DEBUG: bool = false;

// ===========================================================================================
// Ast Generator

/// Main entry point for generating AST for a given function target with associated stackless
/// bytecode.
pub fn generate_ast(target: &FunctionTarget) -> Option<Exp> {
    let exp = generate_ast_raw(target)?;
    Some(transform_assigns(
        target,
        transform_conditionals(target, exp),
    ))
}

/// Entry point for raw generation, without prettifying the AST.
pub fn generate_ast_raw(target: &FunctionTarget) -> Option<Exp> {
    // First cleanup the code. In order to make the algorithm work, unnecessary blocks need to
    // be eliminated.
    let cleanup_context = Context::new(target);
    let cleaned_code = cleanup_context.clean_bytecode();
    let mut new_data = target.data.clone();
    new_data.code = cleaned_code;
    let target = FunctionTarget::new(target.func_env, &new_data);

    // Now create a new context for working with the cleaned code.
    let mut ctx = Context::new(&target);

    let unreached_labels = ctx
        // All labels with corresponding blocks in code.
        .forward_cfg
        .blocks()
        .iter()
        .filter_map(|blk_id| ctx.label_of_block(*blk_id))
        .collect();

    let fat_loop_info = match build_loop_info(&target) {
        // Compute the fat loops of this code. A fat loop is a loop with multiple back-edges all
        // sharing the same loop header.
        Ok(loop_info) => loop_info,
        Err(err) => {
            // This happens if the cfg is not reducible.
            // TODO: we may want to have a fallback strategy for this case. We can generate
            //   a big outer loop with a case for each block and a variable holding the current
            //   block number.
            target.global_env().error(
                &target.get_loc(),
                &format!("cannot decompile function: {}", err),
            );
            return None;
        },
    };
    ctx.compute_loop_info(&fat_loop_info);

    // Create the generator and run it.
    let mut gen = Generator {
        block_stack: vec![],
        unreached_labels,
        used_labels: BTreeSet::new(),
        current_attr: None,
        block_order: BTreeMap::new(),
    };
    Some(gen.gen(&ctx))
}

// -------------------------------------------------------------------------------------------
// Data Types

/// Immutable context used for generation.
struct Context<'a> {
    /// The function target.
    target: &'a FunctionTarget<'a>,
    /// Forward control flow graph of the given code.
    forward_cfg: StacklessControlFlowGraph,
    /// Expression builder.
    builder: ExpBuilder<'a>,
    /// Mapping from labels to the code offset they are associated with.
    label_offsets: BTreeMap<Label, CodeOffset>,
    /// Loop headers. These are the labels of the blocks which dominate all other blocks
    /// in a loop.
    loop_headers: BTreeSet<Label>,
    /// A mapping from block label to the associated loop headers, if the block is part of a loop.
    block_to_header: BTreeMap<Label, Label>,
    /// All block labels belonging to a given loop, indexed by the loop header.
    loop_labels: BTreeMap<Label, BTreeSet<Label>>,
    /// All block labels for a given loop header which are _after_ any block in the loop.
    after_loop_labels: BTreeMap<Label, BTreeSet<Label>>,
    /// Back edges, defined by the code offset where the branch or jump is found, and the label
    /// of the loop header.
    back_edges: BTreeSet<(CodeOffset, Label)>,
}

/// Mutable state of the ast generator.
struct Generator {
    /// A stack of blocks which are currently open.
    block_stack: Vec<BlockInfo>,
    /// The labels for forward jumps which are not yet reached.
    unreached_labels: BTreeSet<Label>,
    /// The labels which have been used so far in jumps or branches.
    used_labels: BTreeSet<Label>,
    /// The attribute of the current bytecode instruction processed.
    current_attr: Option<AttrId>,
    /// A block ordering, maps each block id to an offset which determines
    /// its order.
    block_order: BTreeMap<BlockId, usize>,
}

/// Information about a block currently processed.
#[derive(Clone)]
struct BlockInfo {
    /// Statements accumulated so far.
    stms: Vec<Exp>,
    /// A break label (forward jump) assigned to this block.
    break_label: Option<Label>,
    /// A continue label (backward jump) assigned to this block.
    continue_label: Option<Label>,
}

// -------------------------------------------------------------------------------------------
// Generator Context

impl<'a> Context<'a> {
    fn new(target: &'a FunctionTarget) -> Self {
        let code = target.get_bytecode();
        Self {
            target,
            forward_cfg: StacklessControlFlowGraph::new_forward(code),
            builder: ExpBuilder::new(target.global_env()),
            label_offsets: Bytecode::label_offsets(code),
            loop_headers: Default::default(),
            block_to_header: Default::default(),
            loop_labels: Default::default(),
            after_loop_labels: Default::default(),
            back_edges: Default::default(),
        }
    }

    /// Cleans up the bytecode. To make the algorithm work, the following requirements
    /// have to be met:
    /// 1. There must be no directly adjacent blocks B1 -> B2 such that B1 has no
    ///    other outgoing edges, and B2 has no other incoming. Rather those blocks
    ///    need to be merged into one. Otherwise, the algorithm runs into trouble with
    ///    unwanted interleaving of such blocks if they are not produced adjacently in
    ///    the topological order.
    /// 2. There must be no fallthrough blocks. Rather each block must be terminated
    ///    by one of branch, jump, return, or abort. This is more for help of the code
    ///    here to simplify the viewpoint on the resulting CFG.
    /// 3. There must not be stub blocks which just forward a jump, as in
    ///    `label L1; goto L2`. In this case, we substitute `L1` by `L2`.
    ///     Given a dead loop like `loop continue`, the substitutions will
    ///     form a cycle like L1->L2->L3--->L1. In this case, all labels will be
    ///     substituted with the last one, L3.
    fn clean_bytecode(self) -> Vec<Bytecode> {
        // Compute # of incoming edges for each block.
        let mut incoming_count = BTreeMap::<BlockId, usize>::new();
        for blk_id in self.forward_cfg.blocks() {
            for succ in self.forward_cfg.successors(blk_id) {
                *incoming_count.entry(*succ).or_default() += 1
            }
        }
        // Build a label substitution for stubs.
        let mut label_subst = BTreeMap::new();

        for blk_id in self.forward_cfg.blocks() {
            let block_code = self.code_for_block(blk_id);
            if block_code.len() == 2 {
                if let (Bytecode::Label(_, label1), Bytecode::Jump(_, label2)) =
                    (&block_code[0], &block_code[1])
                {
                    // When only a substitution does not create a cycle, we add it.
                    if !Self::cyclic_label_subst_detected(*label1, *label2, &label_subst) {
                        label_subst.insert(*label1, *label2);
                    }
                }
            }
        }
        let substitute_label = |mut label: Label| {
            let mut visited = BTreeSet::new();
            while let Some(s) = label_subst.get(&label) {
                // This assert should always hold as we have prevented cycles
                // when building the label_subst map.
                assert!(
                    visited.insert(label),
                    "label_subst is acyclic by construction"
                );
                label = *s;
            }
            label
        };
        // Traverse all blocks and merge them as needed.
        let mut todo = vec![self.forward_cfg.entry_block()];
        let mut done = BTreeSet::new();
        let mut result = vec![];
        while let Some(mut blk_id) = todo.pop() {
            if !done.insert(blk_id) {
                continue;
            }
            let mut block_code = self.code_for_block(blk_id);
            loop {
                result.extend(block_code.iter().cloned());
                let succs = self.forward_cfg.successors(blk_id);
                if succs.len() == 1 {
                    let succ = *succs.first().unwrap();
                    if incoming_count[&succ] == 1 {
                        // Fold this block into previous one
                        if matches!(result.last(), Some(Bytecode::Jump(..))) {
                            // Remove the now unnecessary Jump
                            result.pop();
                        }
                        // Continue with this block.
                        blk_id = succ;
                        block_code = self.code_for_block(blk_id);
                        if matches!(block_code.first(), Some(Bytecode::Label(..))) {
                            // Skip label as it is not needed any more
                            block_code = &block_code[1..];
                        }
                        continue;
                    }

                    // If the result doesn't terminate with a branch, add a Jump to make
                    // the fallthrough explicit, but only if it is not an empty block
                    if !block_code.is_empty() {
                        let last = result.last().expect("expected non empty block");
                        if !last.is_branching() {
                            if let Some(label) = self.label_of_block(succ) {
                                result.push(Bytecode::Jump(last.get_attr_id(), label))
                            }
                        }
                    }
                }
                // Substitute any labels in the block terminator
                match result.last_mut() {
                    Some(Bytecode::Jump(_, label)) => *label = substitute_label(*label),
                    Some(Bytecode::Branch(_, if_true, if_false, _)) => {
                        *if_true = substitute_label(*if_true);
                        *if_false = substitute_label(*if_false);
                    },
                    _ => {},
                }
                // Map the successors to those implied by label substitution, and add
                // them to the top of the work stack.
                todo.extend(
                    succs
                        .iter()
                        .filter_map(|b| {
                            self.label_of_block(*b)
                                .map(|l| self.block_of_label(substitute_label(l)))
                        })
                        // revert so first in succs order processed first
                        .rev(),
                );
                break;
            }
        }
        result
    }

    /// Helper function to detect if a label substitution creates a cycle.
    fn cyclic_label_subst_detected(
        label1: Label,
        label2: Label,
        label_subst: &BTreeMap<Label, Label>,
    ) -> bool {
        if label1 == label2 {
            return true;
        }
        // starting from `label2`, recursively replace the label and see if we go back to `label1`.
        // why no endless iteration: label_subst has no cycles!
        let mut target = label2;
        while let Some(s) = label_subst.get(&target) {
            if *s == label1 {
                return true;
            }
            target = *s;
        }
        false
    }

    /// Helper to compute information about loops.
    fn compute_loop_info(&mut self, loop_info: &FatLoopFunctionInfo) {
        let backward_cfg = StacklessControlFlowGraph::new_backward(self.code(), true);
        for (header, fat_loop) in &loop_info.fat_loops {
            self.loop_headers.insert(*header);
            // Compute all blocks which are part of this loop. For this we exploit
            // that the loop header dominates all blocks of the loop.
            let mut todo = vec![];
            for code_offset in &fat_loop.back_edges {
                self.back_edges.insert((*code_offset, *header));
                // Collect the block ids of the blocks which have back edges.
                // This is from where traversal is started.
                todo.push(backward_cfg.enclosing_block(*code_offset));
            }
            let mut loop_blocks = BTreeSet::<Label>::new();
            // Include the header in the result/visited set. Since all paths are
            // dominated by the header, the search is terminated via the
            // header.
            loop_blocks.insert(*header);
            self.block_to_header.insert(*header, *header);
            while let Some(blk_id) = todo.pop() {
                let label = self
                    .label_of_block(blk_id)
                    .expect("expected block to have a label");
                if loop_blocks.insert(label) {
                    self.block_to_header.insert(label, *header);
                    todo.extend(backward_cfg.successors(blk_id))
                }
            }
            // Now compute all blocks after this loop
            let mut after_loop_blocks = BTreeSet::new();
            for blk_label in &loop_blocks {
                let outside_succs = self
                    .successor_labels(*blk_label)
                    .filter(|l| !loop_blocks.contains(l));
                after_loop_blocks.extend(outside_succs);
            }
            if DEBUG {
                debug!(
                    "loop at {} blocks {} after blocks {}",
                    header,
                    loop_blocks.iter().map(|l| l.to_string()).join(","),
                    after_loop_blocks.iter().map(|l| l.to_string()).join(","),
                )
            }
            // Store result
            self.loop_labels.insert(*header, loop_blocks);
            self.after_loop_labels.insert(*header, after_loop_blocks);
        }
    }

    /// Return global env.
    fn env(&self) -> &GlobalEnv {
        self.target.global_env()
    }

    /// Determine the reference kind of a temporary.
    fn ref_kind(&self, temp: TempIndex) -> ReferenceKind {
        self.target
            .get_local_type(temp)
            .ref_kind()
            .unwrap_or(ReferenceKind::Immutable)
    }

    /// Return the code of the current function.
    fn code(&self) -> &[Bytecode] {
        self.target.get_bytecode()
    }

    /// Return the code for the block of the function.
    fn code_for_block(&self, id: BlockId) -> &[Bytecode] {
        &self.code()[self.forward_cfg.code_range(id)]
    }

    /// Returns the block in which the label is defined.
    fn block_of_label(&self, label: Label) -> BlockId {
        self.forward_cfg.enclosing_block(
            *self
                .label_offsets
                .get(&label)
                .expect("expected label has code offset"),
        )
    }

    /// Returns the label of the block, if available.
    fn label_of_block(&self, block_id: BlockId) -> Option<Label> {
        Self::get_label_of_block_from_code(self.code_for_block(block_id))
    }

    fn get_label_of_block_from_code(code: &[Bytecode]) -> Option<Label> {
        if let Some(Bytecode::Label(_, label)) = code.first() {
            Some(*label)
        } else {
            None
        }
    }

    /// Returns labels of successor blocks.
    fn successor_labels(&self, label: Label) -> impl Iterator<Item = Label> + '_ {
        self.forward_cfg
            .successors(self.block_of_label(label))
            .iter()
            .filter_map(|b| self.label_of_block(*b))
    }

    /// Returns true of the edge `from` block `to` block is a back edge.
    fn is_back_edge(&self, from: BlockId, to: BlockId) -> bool {
        let range = self.forward_cfg.code_range(from);
        if !range.is_empty() {
            let code_offset = (range.end - 1) as CodeOffset;
            if let Some(label) = self.label_of_block(to) {
                if self.back_edges.contains(&(code_offset, label)) {
                    return true;
                }
            }
        }
        false
    }
}

// -------------------------------------------------------------------------------------------
// Generator Core Logic

impl Generator {
    /// Run the generator.
    fn gen(&mut self, ctx: &Context) -> Exp {
        let mut blocks = ctx.forward_cfg.blocks();
        // Sort blocks topologically.
        self.sort_blocks(ctx, &mut blocks);
        // Remember the order
        self.block_order = blocks
            .iter()
            .cloned()
            .enumerate()
            .map(|(pos, blk_id)| (blk_id, pos))
            .collect();
        // Push a virtual block onto the stack to collect outer statements.
        self.block_stack.push(BlockInfo {
            stms: vec![],
            break_label: None,
            continue_label: None,
        });
        // Process blocks in the determined order.
        for i in 0..blocks.len() {
            let blk_id = blocks[i];
            if ctx.code_for_block(blk_id).is_empty() {
                // Dummy block, just continue.
                continue;
            }
            self.gen_block(ctx, blk_id, &blocks[i + 1..])
        }
        while self.block_stack.len() > 1 {
            self.close_block(ctx)
        }
        let BlockInfo { stms, .. } = self.block_stack.pop().unwrap();
        ctx.builder.seq(&self.current_loc(ctx), stms)
    }

    /// Topological sort blocks using forward dependencies only, and
    /// ignoring any back jumps. We need to use a sort algorithm here which
    /// produces the sets of independent blocks as we still need to
    /// make a good choice within those blocks. Apparently, `petgraph` does not
    /// give this functionality, so we use crate `topological_sort`.
    fn sort_blocks(&self, ctx: &Context, blocks: &mut Vec<BlockId>) {
        // Construct the partial order derived from the control flow graph.
        let mut top_sort = TopologicalSort::<BlockId>::new();
        let original_blocks = std::mem::take(blocks);
        for blk_id in original_blocks {
            for succ in ctx.forward_cfg.successors(blk_id) {
                if ctx.is_back_edge(blk_id, *succ) {
                    continue;
                }
                top_sort.add_dependency(blk_id, *succ)
            }
        }
        // Add virtual edges to ensure that all blocks of a given loop are before
        // any blocks after that loop. This is a requirement for the algorithm to work.
        for header in &ctx.loop_headers {
            for after_loop_label in &ctx.after_loop_labels[header] {
                for loop_block_label in &ctx.loop_labels[header] {
                    // Only when the new virtual edge does not bring a loop back (without considering the back edges),
                    // we add it!
                    let source_block = ctx.block_of_label(*loop_block_label);
                    let dest_block = ctx.block_of_label(*after_loop_label);
                    let edge_filter = |from: BlockId, to: BlockId| !ctx.is_back_edge(from, to);
                    if !ctx
                        .forward_cfg
                        .reachable_blocks(dest_block, edge_filter)
                        .contains(&source_block)
                    {
                        top_sort.add_dependency(
                            ctx.block_of_label(*loop_block_label),
                            ctx.block_of_label(*after_loop_label),
                        )
                    }
                }
            }
        }

        loop {
            // Peek the group of blocks which are available according to the partial order.
            // We select one of them below.
            let group = top_sort.peek_all();
            if group.is_empty() {
                break;
            }
            // Select the smallest of the group according to the following order:
            // (1) A block belonging to an active loop is smaller.
            // (2) Next, according the way blocks are terminated. This is semantically
            //     not relevant, but leads to better readable code, e.g. abort
            //     first.
            // (2) Finally, which is earlier in the code as produced by the DFS ordering of blocks
            //     in cleanup.
            let current_loop = blocks
                .last()
                .and_then(|blk_id| ctx.label_of_block(*blk_id))
                .and_then(|l| ctx.block_to_header.get(&l))
                .cloned();
            let loop_priority = |b1: BlockId| -> usize {
                if current_loop
                    .and_then(|header| {
                        ctx.label_of_block(b1)
                            .map(|l| ctx.loop_labels[&header].contains(&l))
                    })
                    .unwrap_or(false)
                {
                    // Block has higher priority since it belongs to active loop
                    0
                } else {
                    1
                }
            };
            let terminator_priority = |blk: BlockId| -> usize {
                use Bytecode::*;
                match ctx.code_for_block(blk).last() {
                    None => 0,
                    Some(Abort(..)) => 1,
                    Some(Jump(..)) => 2,
                    Some(Branch(..)) => 3,
                    Some(Ret(..)) => 4,
                    _ => panic!("unexpected block terminator"),
                }
            };
            let min = group
                .iter()
                .copied()
                .copied()
                .reduce(|b1, b2| {
                    match loop_priority(b1).cmp(&loop_priority(b2)).then_with(|| {
                        terminator_priority(b1)
                            .cmp(&terminator_priority(b2))
                            .then_with(|| {
                                ctx.forward_cfg
                                    .code_range(b1)
                                    .start
                                    .cmp(&ctx.forward_cfg.code_range(b2).start)
                            })
                    }) {
                        Ordering::Less | Ordering::Equal => b1,
                        Ordering::Greater => b2,
                    }
                })
                .expect("non-empty `group`");
            // Draw a virtual edge from the smallest node to all others, so next time
            // we do top_sort.pop, we get the chosen one.
            // What is the point of these edges? The 2nd pop will put the
            // successors of the chosen one side-by-side with the non-chosen, allowing
            // to traverse deeper in neighbors of the former. (Like additional loop
            // blocks.) This allows to generate a tailored DFS order.
            for other in group.into_iter().cloned().collect_vec() {
                if other != min {
                    top_sort.add_dependency(min, other)
                }
            }
            debug_assert_eq!(min, top_sort.pop().expect("expected order consistent"));
            blocks.push(min);
        }
        assert!(top_sort.is_empty(), "unexpected cycle in forward jumps");
        if DEBUG {
            self.dprint_blocks(ctx, "sorted", blocks.iter().copied())
        }
    }

    /// Process the given block, with subsequent blocks in the topological order in
    /// the `rest` parameter.
    fn gen_block(&mut self, ctx: &Context, block_id: BlockId, rest: &[BlockId]) {
        use Bytecode::*;

        let block_code = ctx.code_for_block(block_id);
        let next_block_label = rest.first().and_then(|id| ctx.label_of_block(*id));

        for bc in block_code.iter() {
            self.set_current_attr(ctx, bc.get_attr_id());
            match bc {
                // Instructions dealing with control flow
                Label(_, label) => {
                    // Mark the label as reached.
                    self.label_reached(ctx, *label);
                    // If this is the header of a loop, open a loop block
                    if ctx.loop_headers.contains(label) {
                        self.block_stack.push(BlockInfo {
                            stms: vec![],
                            break_label: None,
                            continue_label: Some(*label),
                        });
                    }
                },
                Ret(_, temps) => {
                    let stm = ExpData::Return(
                        self.new_stm_node_id(ctx),
                        self.make_temp_tuple(ctx, temps),
                    );
                    self.add_stm(stm);
                },
                Abort(_, temp) => {
                    let temp = self.make_temp(ctx, *temp);
                    let stm =
                        ExpData::Call(self.new_stm_node_id(ctx), Operation::Abort, vec![temp]);
                    self.add_stm(stm);
                },
                Branch(_, if_true, if_false, cond) => {
                    self.gen_branch(ctx, next_block_label, *cond, *if_true, *if_false);
                },
                Jump(_, target) => {
                    self.gen_jump(ctx, next_block_label, *target);
                },
                // Other instructions
                Nop(_) => {},
                Assign(_, lhs, rhs, _) => {
                    let stm = ExpData::Assign(
                        self.new_stm_node_id(ctx),
                        self.make_temp_pat(ctx, *lhs),
                        self.make_temp(ctx, *rhs),
                    );
                    self.add_stm(stm)
                },
                Call(_, dests, oper, srcs, _) => self.gen_call(ctx, dests, oper, srcs),
                Load(_, temp, value) => {
                    let value_id = self.new_node_id(ctx, ctx.target.get_local_type(*temp).clone());
                    let stm = ExpData::Assign(
                        self.new_stm_node_id(ctx),
                        self.make_temp_pat(ctx, *temp),
                        ExpData::Value(value_id, value.to_model_value()).into_exp(),
                    )
                    .into_exp();
                    self.add_stm(stm)
                },
                SpecBlock(_, _) | SaveMem(_, _, _) | SaveSpecVar(_, _, _) | Prop(_, _, _) => {
                    unimplemented!("ast generation of specs")
                },
            }
        }
    }

    /// Process a branch instruction.
    fn gen_branch(
        &mut self,
        ctx: &Context,
        next_block_label: Option<Label>,
        cond: TempIndex,
        if_true: Label,
        if_false: Label,
    ) {
        let cond = self.make_temp(ctx, cond);
        if let Some(nest) = self.find_continue_nest(ctx, if_true) {
            // This a `continue` of an outer loop
            self.used_labels.insert(if_true);
            self.add_stm(
                ctx.builder
                    .if_(cond, ctx.builder.continue_(&self.current_loc(ctx), nest)),
            );
            // Do the `else` as jump
            self.gen_jump(ctx, next_block_label, if_false)
        } else if let Some(nest) = self.find_continue_nest(ctx, if_false) {
            // Continue with negated condition
            self.used_labels.insert(if_false);
            self.add_stm(ctx.builder.if_(
                ctx.builder.not(cond),
                ctx.builder.continue_(&self.current_loc(ctx), nest),
            ));
            // Do the `if` as jump
            self.gen_jump(ctx, next_block_label, if_true)
        } else if let Some(nest) = self.find_break_nest(ctx, if_true) {
            self.used_labels.insert(if_true);
            self.add_stm(
                ctx.builder
                    .if_(cond, ctx.builder.break_(&self.current_loc(ctx), nest)),
            );
            // Do the `else` as jump
            self.gen_jump(ctx, next_block_label, if_false)
        } else if let Some(nest) = self.find_break_nest(ctx, if_false) {
            self.used_labels.insert(if_false);
            self.add_stm(ctx.builder.if_(
                ctx.builder.not(cond),
                ctx.builder.break_(&self.current_loc(ctx), nest),
            ));
            // Do the `if` as jump
            self.gen_jump(ctx, next_block_label, if_true)
        } else {
            // Both are forward jumps. Determine whether false branch is a better fall through.
            let (negated_cond, if_true, if_false) = if Some(if_false) == next_block_label {
                (cond, if_false, if_true)
            } else {
                (self.make_not(ctx, cond), if_true, if_false)
            };
            // Push a block such we generate code as follows:
            // ```
            //   block {
            //     if !cond break;
            //     <if_true>
            //   }
            //   <if_false>
            // ```
            self.add_block_to_stack(
                ctx,
                BlockInfo {
                    stms: vec![],
                    break_label: Some(if_false),
                    continue_label: None,
                },
                if_false,
            );
            // We need to break out from all the inner loops!
            let nest = self
                .find_break_nest(ctx, if_false)
                .expect("the newly added block must exist");
            self.used_labels.insert(if_false);
            self.add_stm(ctx.builder.if_(
                negated_cond,
                ctx.builder.break_(&self.current_loc(ctx), nest),
            ));
            self.gen_jump(ctx, next_block_label, if_true)
        }
    }

    fn gen_jump(&mut self, ctx: &Context, next_block_label: Option<Label>, target: Label) {
        self.used_labels.insert(target);
        if next_block_label != Some(target) {
            if let Some(nest) = self.find_continue_nest(ctx, target) {
                // continue loop
                self.add_stm(ctx.builder.continue_(&self.current_loc(ctx), nest))
            } else if let Some(nest) = self.find_break_nest(ctx, target) {
                // bind to an existing outer block for forward jump
                self.add_stm(ctx.builder.break_(&self.current_loc(ctx), nest));
            } else {
                // we need to create a new block and add to the stack
                let new_block = BlockInfo {
                    stms: vec![],
                    break_label: Some(target),
                    continue_label: None,
                };
                self.add_block_to_stack(ctx, new_block, target);
                self.add_stm(
                    ctx.builder.break_(
                        &self.current_loc(ctx),
                        self.find_break_nest(ctx, target)
                            .expect("expected label assigned"),
                    ),
                );
            }
        }
    }

    /// Adds a new block for the given target to the block stack. This searches the stack
    /// to find the point under which to nest the given block.
    fn add_block_to_stack(&mut self, ctx: &Context, block_info: BlockInfo, target: Label) {
        if let Some((idx, _)) = self.block_stack.iter().rev().find_position(|info| {
            match info {
                BlockInfo {
                    continue_label: Some(header),
                    ..
                } => {
                    // If the target block is part of this loop, it must be nested inside the loop
                    ctx.loop_labels[header].contains(&target)
                },
                BlockInfo {
                    break_label: Some(label),
                    ..
                } => {
                    // If the target block is before this block, it must be nested inside the block
                    self.label_comes_after(ctx, *label, target)
                },
                _ => false,
            }
        }) {
            // Insert nested in the other block.
            self.block_stack
                .insert(self.block_stack.len() - idx, block_info)
        } else {
            // Insert at top-level, beneath the virtual root block
            self.block_stack.insert(1, block_info)
        }
    }

    /// Returns true if the first label is defined afterward in the code. This can
    /// use the code offset for sorted blocks.
    fn label_comes_after(&self, ctx: &Context, label: Label, other_label: Label) -> bool {
        self.block_order[&ctx.block_of_label(label)]
            > self.block_order[&ctx.block_of_label(other_label)]
    }

    fn find_continue_nest(&self, _ctx: &Context, label: Label) -> Option<usize> {
        for (nest, info) in self.block_stack.iter().rev().enumerate() {
            if info.continue_label.map(|l| l == label).unwrap_or(false) {
                return Some(nest);
            }
        }
        None
    }

    fn find_break_nest(&self, _ctx: &Context, label: Label) -> Option<usize> {
        for (nest, info) in self.block_stack.iter().rev().enumerate() {
            if info.break_label.map(|l| l == label).unwrap_or(false) {
                return Some(nest);
            }
        }
        None
    }

    fn close_block(&mut self, ctx: &Context) {
        if DEBUG {
            self.dprint_stack(ctx, "closing", self.block_stack.iter().rev().take(1));
        }
        let mut stms = self.block_stack.pop().unwrap().stms;

        // The last statement of a block which is not already terminated must have a break
        let needs_break = stms.is_empty()
            || !matches!(
                stms.last().unwrap().as_ref(),
                ExpData::LoopCont(..)
                    | ExpData::Return(..)
                    | ExpData::Call(_, Operation::Abort, ..)
            );
        if needs_break {
            stms.push(ctx.builder.break_(&self.current_loc(ctx), 0))
        }

        // Create a loop and add to parent
        let body = ctx.builder.seq(&self.current_loc(ctx), stms);
        let stm = ctx.builder.loop_(body);
        self.add_stm(stm)
    }

    /// Mark the given label as reached and close all blocks effected by this.
    /// Once a label is reached, it cannot be referenced after this point
    /// with a forward jump.
    ///
    /// A block is closed under the following conditions:
    /// 1. It's a loop header and the reached label is not part of the loop blocks
    /// 2. Its break label is set to one of the reached labels.
    /// 2. It has an unbound break label and is enclosed by a block as in (1)
    fn label_reached(&mut self, ctx: &Context, label: Label) {
        self.unreached_labels.remove(&label);
        if DEBUG {
            self.dprint_stack(
                ctx,
                &format!("reaching {}", label),
                self.block_stack.iter().rev(),
            );
        }

        // Close blocks as result of reaching this label
        while self.block_stack.len() > 1 {
            match self.block_stack.last().unwrap() {
                BlockInfo {
                    continue_label: Some(header),
                    ..
                } if !ctx.loop_labels[header].contains(&label) => {
                    // The loop block is closed because the reached label is not part of it
                    self.close_block(ctx);
                    // Continue closing outer blocks
                },
                BlockInfo {
                    break_label: Some(break_label),
                    ..
                } => {
                    if break_label == &label {
                        self.close_block(ctx);
                    } else {
                        // The label must not appear anywhere at an outer level, otherwise
                        // we violated the invariants that blocks must not overlap
                        assert!(
                            !self
                                .block_stack
                                .iter()
                                .any(|i| i.break_label == Some(label)),
                            "invalid block nesting: expecting {} but reached {}",
                            break_label,
                            label
                        )
                    }
                    // Stop closing outer blocks
                    break;
                },
                _ => break,
            }
        }
        if DEBUG {
            self.dprint_stack(
                ctx,
                &format!("after reaching {}", label),
                self.block_stack.iter().rev(),
            );
        }
    }

    fn gen_call(
        &mut self,
        ctx: &Context,
        dests: &[TempIndex],
        oper: &BytecodeOperation,
        srcs: &[TempIndex],
    ) {
        use BytecodeOperation::*;
        match oper {
            Function(mid, fid, inst) => self.gen_call_stm(
                ctx,
                Some(inst),
                dests,
                Operation::MoveFunction(*mid, *fid),
                srcs,
            ),
            Closure(mid, fid, inst, closure_mask) => self.gen_call_stm(
                ctx,
                Some(inst),
                dests,
                Operation::Closure(*mid, *fid, *closure_mask),
                srcs,
            ),
            Invoke => self.gen_invoke(ctx, dests, srcs),
            Pack(mid, sid, inst) => {
                self.gen_call_stm(
                    ctx,
                    Some(inst),
                    dests,
                    Operation::Pack(*mid, *sid, None),
                    srcs,
                );
            },
            Unpack(mid, sid, inst) => {
                let qsid = mid.qualified_inst(*sid, inst.clone());
                let rhs = self.make_temp(ctx, srcs[0]);
                self.gen_match(ctx, dests, qsid, None, rhs);
            },
            MoveTo(_, _, inst) => {
                self.gen_call_stm(ctx, Some(inst), dests, Operation::MoveTo, srcs);
            },
            MoveFrom(_, _, inst) => {
                self.gen_call_stm(ctx, Some(inst), dests, Operation::MoveFrom, srcs);
            },
            Exists(_, _, inst) => {
                self.gen_call_stm(ctx, Some(inst), dests, Operation::Exists(None), srcs);
            },
            TestVariant(mid, sid, variant, inst) => {
                self.gen_call_stm(
                    ctx,
                    Some(inst),
                    dests,
                    Operation::TestVariants(*mid, *sid, vec![*variant]),
                    srcs,
                );
            },
            PackVariant(mid, sid, variant, inst) => {
                self.gen_call_stm(
                    ctx,
                    Some(inst),
                    dests,
                    Operation::Pack(*mid, *sid, Some(*variant)),
                    srcs,
                );
            },
            UnpackVariant(mid, sid, variant, inst) => {
                let qsid = mid.qualified_inst(*sid, inst.clone());
                let rhs = self.make_temp(ctx, srcs[0]);
                self.gen_match(ctx, dests, qsid, Some(*variant), rhs);
            },
            BorrowGlobal(_, _, inst) => self.gen_call_stm(
                ctx,
                Some(inst),
                dests,
                Operation::BorrowGlobal(ctx.ref_kind(dests[0])),
                srcs,
            ),
            BorrowLoc => self.gen_call_stm(
                ctx,
                None,
                dests,
                Operation::Borrow(ctx.ref_kind(dests[0])),
                srcs,
            ),
            BorrowField(mid, sid, _, field_offset) => {
                let struct_env = ctx.env().get_struct(mid.qualified(*sid));
                let field_id = struct_env.get_field_by_offset(*field_offset).get_id();
                self.gen_call_stm(
                    ctx,
                    None,
                    dests,
                    Operation::Select(*mid, *sid, field_id),
                    srcs,
                )
            },
            BorrowVariantField(mid, sid, variants, _inst, field_offset) => {
                let struct_env = ctx.env().get_struct(mid.qualified(*sid));
                let field_ids = variants
                    .iter()
                    .map(|v| {
                        struct_env
                            .get_field_by_offset_optional_variant(Some(*v), *field_offset)
                            .get_id()
                    })
                    .collect();
                self.gen_call_stm(
                    ctx,
                    None,
                    dests,
                    Operation::SelectVariants(*mid, *sid, field_ids),
                    srcs,
                )
            },
            Drop | Release => {
                // Do nothing
            },
            ReadRef => self.gen_call_stm(ctx, None, dests, Operation::Deref, srcs),
            WriteRef => {
                let stm = ExpData::Mutate(
                    self.new_stm_node_id(ctx),
                    self.make_temp(ctx, srcs[0]),
                    self.make_temp(ctx, srcs[1]),
                );
                self.add_stm(stm)
            },
            FreezeRef(explicit) => {
                self.gen_call_stm(ctx, None, dests, Operation::Freeze(*explicit), srcs)
            },
            Vector => self.gen_call_stm(ctx, None, dests, Operation::Vector, srcs),
            CastU8 | CastU16 | CastU32 | CastU64 | CastU128 | CastU256 => {
                self.gen_call_stm(ctx, None, dests, Operation::Cast, srcs)
            },
            Not => self.gen_call_stm(ctx, None, dests, Operation::Not, srcs),
            Add => self.gen_call_stm(ctx, None, dests, Operation::Add, srcs),
            Sub => self.gen_call_stm(ctx, None, dests, Operation::Sub, srcs),
            Mul => self.gen_call_stm(ctx, None, dests, Operation::Mul, srcs),
            Div => self.gen_call_stm(ctx, None, dests, Operation::Div, srcs),
            Mod => self.gen_call_stm(ctx, None, dests, Operation::Mod, srcs),
            BitAnd => self.gen_call_stm(ctx, None, dests, Operation::BitAnd, srcs),
            BitOr => self.gen_call_stm(ctx, None, dests, Operation::BitOr, srcs),
            Xor => self.gen_call_stm(ctx, None, dests, Operation::Xor, srcs),
            Shl => self.gen_call_stm(ctx, None, dests, Operation::Shl, srcs),
            Shr => self.gen_call_stm(ctx, None, dests, Operation::Shr, srcs),
            Lt => self.gen_call_stm(ctx, None, dests, Operation::Lt, srcs),
            Gt => self.gen_call_stm(ctx, None, dests, Operation::Gt, srcs),
            Le => self.gen_call_stm(ctx, None, dests, Operation::Le, srcs),
            Ge => self.gen_call_stm(ctx, None, dests, Operation::Ge, srcs),
            Or => self.gen_call_stm(ctx, None, dests, Operation::Or, srcs),
            And => self.gen_call_stm(ctx, None, dests, Operation::And, srcs),
            Eq => self.gen_call_stm(ctx, None, dests, Operation::Eq, srcs),
            Neq => self.gen_call_stm(ctx, None, dests, Operation::Neq, srcs),

            OpaqueCallBegin(_, _, _)
            | OpaqueCallEnd(_, _, _)
            | IsParent(_, _)
            | WriteBack(_, _)
            | UnpackRef
            | PackRef
            | UnpackRefDeep
            | PackRefDeep
            | GetField(_, _, _, _)
            | GetVariantField(_, _, _, _, _)
            | GetGlobal(_, _, _)
            | Uninit
            | Havoc(_)
            | Stop
            | TraceLocal(_)
            | TraceReturn(_)
            | TraceAbort
            | TraceExp(_, _)
            | TraceGlobalMem(_)
            | EmitEvent
            | EventStoreDiverge => {
                panic!("specification operation not supported: {:?}", oper)
            },
        }
    }

    fn gen_call_stm(
        &mut self,
        ctx: &Context,
        inst: Option<&Vec<Type>>,
        dests: &[TempIndex],
        oper: Operation,
        srcs: &[TempIndex],
    ) {
        let ty = Type::tuple(
            dests
                .iter()
                .map(|d| ctx.target.get_local_type(*d).clone())
                .collect(),
        );
        let call_id = self.new_node_id(ctx, ty);
        if let Some(inst) = inst {
            ctx.env().set_node_instantiation(call_id, inst.to_vec())
        }
        let call = ExpData::Call(call_id, oper, self.make_temps(ctx, srcs.iter().copied()));
        if !dests.is_empty() {
            self.gen_assign(ctx, dests, call)
        } else {
            self.add_stm(call)
        }
    }

    fn gen_invoke(&mut self, ctx: &Context, dests: &[TempIndex], srcs: &[TempIndex]) {
        let ty = Type::tuple(
            dests
                .iter()
                .map(|d| ctx.target.get_local_type(*d).clone())
                .collect(),
        );
        let invoke_id = self.new_node_id(ctx, ty);
        let mut temps = self.make_temps(ctx, srcs.iter().copied());
        let closure = temps.pop().expect("closure must be present for invoke");
        let invoke = ExpData::Invoke(invoke_id, closure, temps);
        if !dests.is_empty() {
            self.gen_assign(ctx, dests, invoke)
        } else {
            self.add_stm(invoke)
        }
    }

    fn gen_match(
        &mut self,
        ctx: &Context,
        dests: &[TempIndex],
        qsid: QualifiedInstId<StructId>,
        variant: Option<Symbol>,
        rhs: Exp,
    ) {
        let pat_id = self.new_node_id(ctx, qsid.to_type());
        let pat = Pattern::Struct(
            pat_id,
            qsid,
            variant,
            dests.iter().map(|d| self.make_temp_pat(ctx, *d)).collect(),
        );
        let stm = ExpData::Assign(self.new_stm_node_id(ctx), pat, rhs);
        self.add_stm(stm)
    }

    fn gen_assign(&mut self, ctx: &Context, dests: &[TempIndex], exp: impl Into<Exp>) {
        let stm = ExpData::Assign(
            self.new_stm_node_id(ctx),
            self.make_temp_pat_tuple(ctx, dests),
            exp.into(),
        );
        self.add_stm(stm)
    }

    fn top_block_mut(&mut self) -> &mut BlockInfo {
        self.block_stack
            .last_mut()
            .expect("expected block stack not be empty")
    }

    fn add_stm(&mut self, exp: impl Into<Exp>) {
        self.top_block_mut().stms.push(exp.into())
    }

    fn make_var_decl(&mut self, ctx: &Context, temp: TempIndex) -> (NodeId, Symbol) {
        let name = if temp < ctx.target.get_parameter_count() {
            ctx.target.get_local_name(temp)
        } else {
            ctx.env().symbol_pool().make(&format!("_t{}", temp))
        };
        let ty = ctx.target.get_local_type(temp);
        let id = self.new_node_id(ctx, ty.clone());
        (id, name)
    }

    fn make_temp(&mut self, ctx: &Context, temp: TempIndex) -> Exp {
        let (id, name) = self.make_var_decl(ctx, temp);
        ExpData::LocalVar(id, name).into_exp()
    }

    fn make_temps(&mut self, ctx: &Context, temps: impl Iterator<Item = TempIndex>) -> Vec<Exp> {
        temps.map(|temp| self.make_temp(ctx, temp)).collect()
    }

    fn make_temp_pat(&mut self, ctx: &Context, temp: TempIndex) -> Pattern {
        let (id, name) = self.make_var_decl(ctx, temp);
        Pattern::Var(id, name)
    }

    fn make_temp_tuple(&mut self, ctx: &Context, temps: &[TempIndex]) -> Exp {
        let mut exps = temps
            .iter()
            .map(|temp| self.make_temp(ctx, *temp))
            .collect_vec();
        if exps.len() == 1 {
            exps.pop().unwrap()
        } else {
            let ty = Type::Tuple(
                exps.iter()
                    .map(|e| ctx.env().get_node_type(e.node_id()))
                    .collect(),
            );
            let node_id = self.new_node_id(ctx, ty);
            ExpData::Call(node_id, Operation::Tuple, exps).into_exp()
        }
    }

    fn make_temp_pat_tuple(&mut self, ctx: &Context, temps: &[TempIndex]) -> Pattern {
        let mut pats = temps
            .iter()
            .map(|temp| self.make_temp_pat(ctx, *temp))
            .collect_vec();
        if pats.len() == 1 {
            pats.pop().unwrap()
        } else {
            let ty = Type::Tuple(
                pats.iter()
                    .map(|p| ctx.env().get_node_type(p.node_id()))
                    .collect(),
            );
            let node_id = self.new_node_id(ctx, ty);
            Pattern::Tuple(node_id, pats)
        }
    }

    fn make_not(&self, ctx: &Context, exp: Exp) -> Exp {
        let node_id = self.clone_node_id(ctx, exp.node_id());
        ExpData::Call(node_id, Operation::Not, vec![exp]).into_exp()
    }

    fn new_node_id(&self, ctx: &Context, ty: Type) -> NodeId {
        ctx.builder.new_node_id(self.current_loc(ctx), ty)
    }

    fn new_stm_node_id(&self, ctx: &Context) -> NodeId {
        self.new_node_id(ctx, Type::unit())
    }

    fn clone_node_id(&self, ctx: &Context, id: NodeId) -> NodeId {
        ctx.builder.clone_node_id(id)
    }

    fn set_current_attr(&mut self, _ctx: &Context, attr_id: AttrId) {
        self.current_attr = Some(attr_id)
    }

    fn current_loc(&self, ctx: &Context) -> Loc {
        self.current_attr
            .map(|attr| ctx.target.get_bytecode_loc(attr))
            .unwrap_or_else(|| ctx.target.get_loc())
    }

    // ----------------------------------------------------------------------------------------
    // Debugging

    fn dprint_blocks(&self, ctx: &Context, note: &str, blocks: impl Iterator<Item = BlockId>) {
        if log_enabled!(Level::Debug) {
            debug!(">> {}", note);
            for blk_id in blocks {
                debug!(
                    "Block #{}{} successors {}",
                    blk_id,
                    if blk_id == ctx.forward_cfg.entry_block() {
                        " entry "
                    } else {
                        ""
                    },
                    ctx.forward_cfg
                        .successors(blk_id)
                        .iter()
                        .map(|s| format!("Block #{}", s))
                        .join(",")
                );
                if ctx.code_for_block(blk_id).is_empty() {
                    debug!("no code")
                } else {
                    debug!(
                        "code range {}..{}",
                        ctx.forward_cfg.code_range(blk_id).start,
                        ctx.forward_cfg.code_range(blk_id).end
                    );
                }

                for bc in ctx.code_for_block(blk_id) {
                    debug!("  {}", bc.display(ctx.target, &BTreeMap::new()))
                }
            }
        }
    }

    fn dprint_stack<'a>(
        &self,
        _ctx: &Context,
        note: &str,
        stack: impl Iterator<Item = &'a BlockInfo>,
    ) {
        if log_enabled!(Level::Debug) {
            debug!(">> {}", note);
            for BlockInfo {
                break_label,
                continue_label,
                ..
            } in stack
            {
                debug!(
                    "  break = {}, continue = {} {{ .. }}",
                    break_label
                        .map(|l| l.to_string())
                        .unwrap_or_else(|| "?".to_string()),
                    continue_label
                        .map(|l| l.to_string())
                        .unwrap_or_else(|| "?".to_string()),
                );
            }
            debug!(
                "  used labels {}, unreached labels {}",
                self.used_labels.iter().map(|l| l.to_string()).join(","),
                self.unreached_labels
                    .iter()
                    .map(|l| l.to_string())
                    .join(",")
            )
        }
    }
}

// =====================================================================================

/// A rewriter which detects if-then and if-then-else patterns in generated
/// loops.
pub fn transform_conditionals(target: &FunctionTarget, exp: Exp) -> Exp {
    let loop_to_cont = exp.compute_loop_bindings().0;
    let builder = ExpBuilder::new(target.global_env());
    IfElseTransformer {
        loop_to_cont,
        builder,
    }
    .rewrite_exp(exp)
}

struct IfElseTransformer<'a> {
    /// Contains bindings of break/continue statements to `loop` expressions in the code.
    /// This maps from the node id to a map of the node ids of such statements, the boolean
    /// indicating whether it is a `continue` (true) or `break`.
    loop_to_cont: BTreeMap<NodeId, BTreeMap<NodeId, bool>>,
    /// The expression builder.
    builder: ExpBuilder<'a>,
}

impl ExpRewriterFunctions for IfElseTransformer<'_> {
    fn rewrite_exp(&mut self, exp: Exp) -> Exp {
        if let Some(result) = self.try_make_if(exp.clone()) {
            self.rewrite_exp_descent(result)
        } else {
            self.rewrite_exp_descent(exp)
        }
    }
}

impl IfElseTransformer<'_> {
    /// Attempts to create an if-then (without else) from the given expression.
    /// This recognizes the pattern below, as produced by the AST
    /// generator:
    ///
    /// ```move
    ///   loop { // no loop header
    ///     ( if (c_i) break; )+
    ///     <then-branch> // does not reference loop
    ///     break|abort|return|continue
    ///   }
    ///
    /// ==>
    ///
    ///   if (!(c1 || .. || cn)) {
    ///     <then-branch> where loop_nest -= 1
    ///   }
    /// ```
    fn try_make_if(&self, exp: Exp) -> Option<Exp> {
        let node_id = exp.node_id();
        let default_loc = self.builder.env().get_node_loc(node_id);

        // Match the pattern as described above
        let (loop_id, body) = match_ok!(exp.as_ref(), ExpData::Loop(_0, _1))?;
        let (cond, rest) = self.builder.match_if_break_list(body.clone())?;
        let then_branch = self.builder.extract_terminated_prefix(
            &default_loc,
            rest,
            0,
            /*allow_exit*/ true,
        )?;

        // Check conditions
        self.check_no_loop_header(*loop_id)?;
        if then_branch.branches_to(0..1) {
            return None;
        }

        // Construct result
        let then_branch = then_branch.rewrite_loop_nest(-1);
        Some(self.builder.if_else(
            self.builder.not(cond),
            then_branch,
            self.builder.nop(&default_loc),
        ))
    }

    fn check_no_loop_header(&self, node_id: NodeId) -> Option<()> {
        if self
            .loop_to_cont
            .get(&node_id)
            .map(|conts| conts.iter().any(|(_, is_cont)| *is_cont))
            .unwrap_or(false)
        {
            None
        } else {
            Some(())
        }
    }
}

// ===================================================================================

/// A rewriter which eliminates single and unused assignments.
pub fn transform_assigns(target: &FunctionTarget, exp: Exp) -> Exp {
    let usage = analyze_usage(target, exp.as_ref());
    let builder = ExpBuilder::new(target.global_env());
    AssignTransformer { usage, builder }.rewrite_exp(exp)
}

/// A rewriter which binds free variables.
pub fn bind_free_vars(target: &FunctionTarget, exp: Exp) -> Exp {
    let usage = analyze_usage(target, exp.as_ref());
    let builder = ExpBuilder::new(target.global_env());
    FreeVariableBinder {
        usage,
        builder,
        // Parameters set to be bound
        bound_vars: vec![target
            .get_parameters()
            .map(|temp| target.get_local_name(temp))
            .collect()],
    }
    .rewrite_exp(exp)
}

struct AssignTransformer<'a> {
    /// Usage information about variables in the expression
    usage: BTreeMap<NodeId, UsageInfo>,
    /// The expression builder.
    builder: ExpBuilder<'a>,
}

#[allow(unused)]
struct FreeVariableBinder<'a> {
    /// Usage information about variables in the expression
    usage: BTreeMap<NodeId, UsageInfo>,
    /// The expression builder.
    builder: ExpBuilder<'a>,
    /// Variables which are bound in outer scopes
    bound_vars: Vec<BTreeSet<Symbol>>,
}

impl ExpRewriterFunctions for AssignTransformer<'_> {
    fn rewrite_exp(&mut self, exp: Exp) -> Exp {
        if let ExpData::Sequence(id, stms) = exp.as_ref() {
            // If this is a sequence, simplify.
            ExpData::Sequence(*id, self.simplify_seq(*id, stms)).into_exp()
        } else {
            self.rewrite_exp_descent(exp)
        }
    }
}

impl AssignTransformer<'_> {
    fn simplify_seq(&mut self, seq_id: NodeId, stms: &[Exp]) -> Vec<Exp> {
        let Some(last) = stms.last() else {
            return vec![];
        };
        let mut after_block_usage = self.usage[&last.node_id()].clone();
        if matches!(last.as_ref(), ExpData::LoopCont(..)) && stms.len() > 1 {
            // TODO: it seems to be weird to need to go back after terminator, but the usage
            //   after the terminator is cleared (because the code there is never used). Lets try
            //   to consolidate this in a better way
            let before_last = &stms[stms.len() - 2];
            if let Some(u) = self.usage.get(&before_last.node_id()) {
                after_block_usage.join(u);
            }
        }
        let mut blocks = vec![];
        let mut new_stms = vec![];
        let mut substitution: BTreeMap<Symbol, Exp> = BTreeMap::new();
        for stm in stms {
            let stm_usage = self.usage[&stm.node_id()].clone();
            match stm.as_ref() {
                // Check whether an assignment can be eliminated because it is used only once.
                // This is often the case with stackless bytecode generated
                // from stack code.
                ExpData::Assign(id, Pattern::Var(_, var), rhs)
                if
                // Cannot be read outside this block
                after_block_usage.read_count(*var) == 0 &&
                    // Must be read zero or once inside the block
                    stm_usage.read_count(*var) <= 1 &&
                    // If it's been written to after, only via this exact statement (this
                    // happens if we are in a loop).
                    stm_usage.is_single_assignment(*var, id) &&
                    // Must not be borrowed after this statement
                    !stm_usage.is_borrowed(*var)
                =>
                    {
                        substitution.insert(
                            *var,
                            self.rewrite_exp(self.builder.unfold(&substitution, rhs.clone())));
                    },
                // Check whether an assignment can be transformed into a let
                // TODO: refine to the correct implementation, the below doesn't work
                //   if variable is already assigned (need reaching definitions).
                /*
                ExpData::Assign(_, pat, rhs)
                // None of the variables in the pattern is used after the block
                if pat.vars().into_iter().all(|(_, var)| after_block_usage.read_count(var) == 0) => {
                    // Save building the block for later when we have the rest of the sequence
                    blocks.push((new_stms, pat.clone(),
                                 self.rewrite_exp(
                                     self.builder.unfold(&substitution, rhs.clone()))));
                    new_stms = vec![];
                }
                 */
                _ => {
                    new_stms.push(self.rewrite_exp(
                        self.builder.unfold(&substitution, stm.clone())))
                },
            }
        }
        let default_loc = self.builder.env().get_node_loc(seq_id);
        // Process all blocks which have been saved for later
        while let Some((prev_stms, pat, def)) = blocks.pop() {
            let block =
                self.builder
                    .block(pat, Some(def), self.builder.seq(&default_loc, new_stms));
            new_stms = prev_stms;
            new_stms.push(block)
        }
        new_stms
    }
}

impl ExpRewriterFunctions for FreeVariableBinder<'_> {
    fn rewrite_exp(&mut self, mut exp: Exp) -> Exp {
        // TODO: this currently just adds lets on outermost level.
        //   Refine this to push lets down to leafs.
        let mut bound = BTreeSet::new();
        exp.clone().visit_free_local_vars(|node_id, var| {
            if bound.insert(var) && !self.bound_vars.iter().any(|b| b.contains(&var)) {
                exp = self.builder.block(
                    Pattern::Var(self.builder.clone_node_id(node_id), var),
                    None,
                    exp.clone(),
                );
            }
        });
        exp
    }
}

// ===================================================================================

/// Usage information about variables in an expression.
#[derive(Default, Clone, AbstractDomain)]
struct UsageInfo {
    /// Variables which are read by and after this expression.
    reads: MapDomain<Symbol, SetDomain<NodeId>>,
    /// Variables which are written by or after this expression.
    writes: MapDomain<Symbol, SetDomain<NodeId>>,
    /// Variables which are borrowed by or after this expression, immutable or mutable.
    borrows: MapDomain<Symbol, SetDomain<NodeId>>,
}

/// Analyze the expression for variable usage and returns a map from node id
/// to the info.
fn analyze_usage(_target: &FunctionTarget, exp: &ExpData) -> BTreeMap<NodeId, UsageInfo> {
    let mut step_fun = |state: &mut UsageInfo, e: &ExpData| {
        use ExpData::*;
        match e {
            Assign(id, pat, rhs) => {
                for (_, var) in pat.vars() {
                    state.add_write(var, *id)
                }
                rhs.visit_free_local_vars(|id, var| state.add_read(var, id))
            },
            Block(id, pat, binding, body) => {
                if let Some(b) = binding {
                    b.visit_free_local_vars(|id, var| state.add_read(var, id))
                }
                for (_, var) in pat.vars() {
                    state.add_write(var, *id)
                }
                body.visit_free_local_vars(|id, var| state.add_read(var, id))
            },
            Call(_, Operation::Borrow(kind), args) => args[0].visit_free_local_vars(|id, var| {
                // Args supposed to be only a single variable, and marking everything in
                // this exp as borrowed is safe.
                if *kind == ReferenceKind::Mutable {
                    state.add_write(var, id)
                }
                state.add_borrow(var, id);
            }),
            _ => e.visit_free_local_vars(|id, var| state.add_read(var, id)),
        }
    };
    let mut analyzer = FixpointAnalyser::new(false, &mut step_fun);
    analyzer.run_until_fixpoint(exp);
    let mut post_state = BTreeMap::new();
    analyzer.compute_post_state(&mut post_state, exp, UsageInfo::default());
    if DEBUG {
        debug!(
            "usage: {}",
            exp.display_with_annotator(_target.global_env(), &|id| {
                if let Some(u) = post_state.get(&id) {
                    u.debug_print(_target.global_env())
                } else {
                    "".to_string()
                }
            })
        );
    }
    post_state
}

impl UsageInfo {
    fn add_read(&mut self, var: Symbol, id: NodeId) {
        self.reads.entry(var).or_default().insert(id);
    }

    fn add_borrow(&mut self, var: Symbol, id: NodeId) {
        self.borrows.entry(var).or_default().insert(id);
    }

    fn add_write(&mut self, var: Symbol, id: NodeId) {
        self.reads.remove(&var);
        self.borrows.remove(&var);
        self.writes.entry(var).or_default().insert(id);
    }

    fn read_count(&self, var: Symbol) -> usize {
        self.reads.get(&var).map(|s| s.len()).unwrap_or(0)
    }

    /// Interpreting this as the post state, check whether a write
    /// at the `at_id` is a single assignment. This is the
    /// case if there is no further assignment after, or if the only
    /// assignment is via the given `at_id` and reached via a loop.
    ///
    /// Notice that this is currently an over-approximation, it
    /// would be perfectly valid to have multiple assignments
    /// if the reaching definitions are unique.
    fn is_single_assignment(&self, var: Symbol, at_id: &NodeId) -> bool {
        self.writes
            .get(&var)
            .map(|s| s.is_empty() || s.len() == 1 && s.contains(at_id))
            .unwrap_or(true)
    }

    fn is_borrowed(&self, var: Symbol) -> bool {
        self.borrows
            .get(&var)
            .map(|s| !s.is_empty())
            .unwrap_or(false)
    }

    #[allow(unused)]
    fn debug_print(&self, env: &GlobalEnv) -> String {
        let disp = |s: &str, d: &MapDomain<Symbol, SetDomain<NodeId>>| {
            if d.is_empty() {
                "".to_string()
            } else {
                format!(
                    "{}={}",
                    s,
                    d.iter()
                        .map(|(v, s)| format!("{}:{}", v.display(env.symbol_pool()), s.len()))
                        .join(",")
                )
            }
        };
        format!(
            "{}{}{}",
            disp("r", &self.reads),
            disp(",w", &self.writes),
            disp(",b", &self.borrows)
        )
    }
}

// ===================================================================================

// A small dataflow analysis framework for ASTs in the form as generated by the
// AST generator:
//
// 1. All control structures (IfElse, Loop, LoopCont) are on top-level and not
//    nested inside expressions.
// 2. There are no Block (let) bindings but just assignments.
//
// We may want to pull this out as a general tool for arbitrary expressions, but right
// now it's tailored for the use case here if we consider this normal form useful
// for other use cases as well.

struct FixpointAnalyser<'a, D, F> {
    forward: bool,
    state: BTreeMap<NodeId, D>,
    changed: JoinResult,
    cont_to_loop: BTreeMap<NodeId, NodeId>,
    loop_to_cont: BTreeMap<NodeId, BTreeMap<NodeId, bool>>,
    step_fun: &'a mut F,
}

impl<'a, D, F> FixpointAnalyser<'a, D, F>
where
    D: AbstractDomain + Default + Clone,
    F: FnMut(&mut D, &ExpData),
{
    fn new(forward: bool, step_fun: &'a mut F) -> Self {
        Self {
            forward,
            state: BTreeMap::new(),
            changed: JoinResult::Unchanged,
            cont_to_loop: BTreeMap::new(),
            loop_to_cont: BTreeMap::new(),
            step_fun,
        }
    }

    fn run_until_fixpoint(&mut self, exp: &ExpData) {
        (self.loop_to_cont, self.cont_to_loop) = exp.compute_loop_bindings();
        loop {
            let mut state = D::default();
            self.changed = JoinResult::Unchanged;
            self.run(&mut state, exp);
            if self.changed == JoinResult::Unchanged {
                break;
            }
        }
    }

    /// Compute a post-state mapping for each node, that is associate the D
    /// of the node following in the control flow.
    fn compute_post_state(
        &self,
        post_state_map: &mut BTreeMap<NodeId, D>,
        exp: &ExpData,
        mut post_state: D,
    ) {
        assert!(!self.forward);
        post_state_map.insert(exp.node_id(), post_state.clone());
        match exp {
            ExpData::Sequence(_, stms) if !stms.is_empty() => {
                for stm in stms.iter().rev() {
                    if let ExpData::LoopCont(cont_id, _, true) = stm.as_ref() {
                        let header = self.cont_to_loop[cont_id];
                        post_state = post_state_map[&header].clone();
                    }
                    self.compute_post_state(post_state_map, stm.as_ref(), post_state);
                    post_state = self.state(&stm.node_id()).cloned().unwrap_or_default();
                }
            },
            ExpData::Loop(id, body) => {
                for (cont_id, is_cont) in &self.loop_to_cont[id] {
                    if *is_cont {
                        post_state_map.insert(*cont_id, post_state.clone());
                    }
                }
                self.compute_post_state(post_state_map, body, post_state)
            },
            ExpData::IfElse(_, _, if_true, if_false) => {
                self.compute_post_state(post_state_map, if_true, post_state.clone());
                self.compute_post_state(post_state_map, if_false, post_state.clone())
            },
            ExpData::Block(_, _, _, body) => {
                self.compute_post_state(post_state_map, body, post_state)
            },
            _ => {
                // leaf
            },
        }
    }

    fn run(&mut self, state: &mut D, exp: &ExpData) {
        use ExpData::*;
        match exp {
            IfElse(id, cond, true_branch, false_branch) => {
                if self.forward {
                    (self.step_fun)(state, cond.as_ref());
                }
                let mut false_state = state.clone();
                self.run(state, true_branch);
                self.run(&mut false_state, false_branch);
                state.join(&false_state);
                if !self.forward {
                    (self.step_fun)(state, cond.as_ref());
                }
                self.join(state, id)
            },
            Block(id, _, _, body) => {
                self.run(state, body);
                self.join(state, id)
            },
            Sequence(id, stms) => {
                if self.forward {
                    for stm in stms {
                        self.run(state, stm)
                    }
                } else {
                    for stm in stms.iter().rev() {
                        self.run(state, stm)
                    }
                }
                self.join(state, id)
            },
            Loop(id, body) => {
                if !self.forward {
                    // On backward analysis, we first need to push the current state to the
                    // breaks of the loops, then analyse the body, and push back
                    // end state to continues. Because the loop has no backwards
                    // entry, clear the state before entering the body.
                    for (cont_id, is_cont) in &self.loop_to_cont[id].clone() {
                        if !*is_cont {
                            self.join(state, cont_id)
                        }
                    }
                    *state = D::default();
                    self.run(state, body.as_ref());
                    for (cont_id, is_cont) in &self.loop_to_cont[id].clone() {
                        if *is_cont {
                            self.join(state, cont_id)
                        }
                    }
                    self.join(state, id)
                } else {
                    // On forward analysis, we need to merge the state of the continues
                    // into the current state, then analyze the body, and then push
                    // the state of the loop breaks into the end state.
                    for (cont_id, is_cont) in &self.loop_to_cont[id].clone() {
                        if *is_cont {
                            self.join(state, cont_id)
                        }
                    }
                    self.run(state, body.as_ref());
                    for (cont_id, is_cont) in &self.loop_to_cont[id].clone() {
                        if !*is_cont {
                            self.join(state, cont_id)
                        }
                    }
                    self.join(state, id)
                }
            },
            LoopCont(id, _, false) if !self.forward => {
                // On backwards analysis and a break, reset state to annotated
                // one
                *state = self.state(id).cloned().unwrap_or_default();
            },
            _ => {
                // All other expressions are treated as "flat", that is, we directly
                // call the step function on them.
                if !self.forward && self.is_terminator(exp) {
                    // Input state is empty
                    *state = D::default();
                }
                (self.step_fun)(state, exp);
                self.join(state, &exp.node_id());
                if self.forward && self.is_terminator(exp) {
                    // Output state is empty
                    *state = D::default();
                }
            },
        }
    }

    fn is_terminator(&self, exp: &ExpData) -> bool {
        matches!(
            exp,
            ExpData::LoopCont(..) | ExpData::Return(..) | ExpData::Call(_, Operation::Abort, ..)
        )
    }

    fn state(&self, id: &NodeId) -> Option<&D> {
        self.state.get(id)
    }

    fn join(&mut self, state: &mut D, id: &NodeId) {
        if let Some(old_state) = self.state.get_mut(id) {
            self.changed |= old_state.join(state);
            *state = old_state.clone()
        } else {
            self.state.insert(*id, state.clone());
            self.changed = JoinResult::Changed
        }
    }
}
